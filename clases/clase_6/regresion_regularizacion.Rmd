---
title: "Regresión lineal y regularización ridge"
author: "Felipe González"
date: Otoño 2015
output: 
  html_document: 
    theme: united
---


Ejemplo de Izenman, *Modern Multivariate Statistical Techniques*.

```{r, warning=FALSE,message=FALSE}
library(glmnet)
library(ggplot2)
library(dplyr)
library(tidyr)
library(readr)
library(arm)
bodyfat <- read_csv('datos/bodyfat.csv')
names(bodyfat)
nrow(bodyfat) 
bodyfat$id <- bodyfat$`[EMPTY]`
bodyfat$`[EMPTY]` <- NULL
head(bodyfat)
```

Short Summary:
Lists estimates of the percentage of body fat determined by underwater
 weighing and various body circumference measurements for 252 men. 

 Classroom use of this data set:
 This data set can be used to illustrate multiple regression techniques.
 Accurate measurement of body fat is inconvenient/costly and it is 
 desirable to have easy methods of estimating body fat that are not' inconvenient/costly.

 More Details:
 A variety of popular health books suggest that the readers assess their
 health, at least in part, by estimating their percentage of body fat. In
 Bailey (1994), for instance, the reader can estimate body fat from tables
 using their age and various skin-fold measurements obtained by using a
 caliper. Other texts give predictive equations for body fat using body 
 circumference measurements (e.g. abdominal circumference) and/or skin-fold
 measurements. See, for instance, Behnke and Wilmore (1974), pp. 66-67;
 Wilmore (1976), p. 247; or Katch and McArdle (1977), pp. 120-132). 
 

 The variables listed below, from left to right, are: 

 - Density determined from underwater weighing
- Percent body fat from Siri's (1956) equation
-  Age (years)
-  Weight (lbs)
-  Height (inches)
-  Neck circumference (cm)
-  Chest circumference (cm)
-  Abdomen 2 circumference (cm)
-  Hip circumference (cm)
-  Thigh circumference (cm)
-  Knee circumference (cm)
-  Ankle circumference (cm)
-  Biceps (extended) circumference (cm)
-  Forearm circumference (cm)
-  Wrist circumference (cm)

Conviene pasar dos variables a métrico:

```{r}
bodyfat$estatura.cm <- 2.54*bodyfat$estatura
bodyfat$peso.kg <- 0.45359237 * bodyfat$peso
bodyfat$densidad <- NULL
bodyfat$estatura <- NULL
bodyfat$peso <- NULL
```


En primer lugar, tenemos que separar una muestra de entrenamiento y una de prueba.
Vamos a seleccionar 60 casos de entrenamiento (generalmente con un conjunto de datos de este
tamaño evaluamos desempeño con validación cruzada, no muestra de prueba. Esto lo veremos más adelante.)

```{r}
N <- 35
set.seed(2805)
indices_entrena <- sample(bodyfat$id, N)
bodyfat_entrena <- filter(bodyfat, id %in% indices_entrena)
bodyfat_prueba <- filter(bodyfat, !(id %in% indices_entrena))

nrow(bodyfat_entrena)
nrow(bodyfat_prueba)
```


Ahora podemos hacer algunos diagnósticos de nuestros datos. Primero los ponemos
en forma larga:


```{r}
head(bodyfat_entrena)

bf_e <- bodyfat_entrena %>%
  gather(variable, valor, -id)
```

Y graficamos distribuciones univariadas:

```{r, warning=FALSE,message=FALSE}

ggplot(bf_e, aes(x=valor)) + facet_wrap(~variable, scales='free_x')+ geom_histogram() 
```

En primer lugar vemos que hay algunas medidas de estatura y tobillo que parecen
muy fuera de su rango. Encontramos los ids:

```{r}
bodyfat_entrena %>%
  filter(estatura.cm < 100) %>% data.frame
```
El primer caso corresponde a una persona de 44 años de 92kg con una estatura de 75cm. Este
es un caso atípico para el que en realidad no queremos hacer predicciones.

El segundo caso es más difícil de diagnosticar:
```{r}
bodyfat_entrena %>%
  filter(tobillo > 30) %>% data.frame
```
```{r, warning=FALSE, message=FALSE}
ggplot(bf_e, aes(x=valor)) + facet_wrap(~variable, scales='free_x')+ geom_histogram() +
  geom_vline(data = filter(bf_e, id==42), aes(xintercept=valor), colour='red')
```

Por lo pronto decidimos quitar el caso con estatura demasiado baja. Esto no siempre ayuda mucho
en la predicción, pero es una técnica que en algunos casos ayuda considerablemente:

```{r, warning=FALSE, message=FALSE}
ids_excluir <- c(42)
ggplot(filter(bf_e, !(id %in% ids_excluir)), aes(x=valor)) + 
  facet_wrap(~variable, scales='free_x')+ geom_histogram() 
```


Preparación de variables
---


En primer lugar, estandarizamos las variables de entrada. Esto facilita la interpretación
del modelo resultante y también mejora el desempeño de muchos algoritmos de entrenamiento. Primero
checamos media y desviación estándar de cada variable:
```{r}
bodyfat_entrena_1 <- filter(bodyfat_entrena, !(id %in% ids_excluir))
bf_e <- bodyfat_entrena_1 %>%
  gather(variable, valor, -id)
media_de <- bf_e %>%
  filter(!(id %in% ids_excluir)) %>%
  group_by(variable) %>%
  summarise(media = mean(valor), de = sd(valor))
media_de
```



Y ahora estandarizamos las variables originales (no es necesario estandarizar la respuesta, 
que es grasacorp). Vamos a crear una función para hacer esto:
```{r}
estandarizar <- function(nuevos_dat, media_de){
  datos_est <- nuevos_dat %>%
    gather(variable, valor, -id) %>%
    group_by(variable) %>%
    filter(variable != 'grasacorp') %>%
    left_join(media_de) %>%
    mutate(valor_st = (valor - media)/de) %>%
    dplyr::select(id, variable, valor_st) %>%
    spread(variable, valor_st) %>%
    left_join(dplyr::select(nuevos_dat, id, grasacorp))
  datos_est
}
```
```{r, warning=FALSE, message=FALSE}
bf_entrena_st <- estandarizar(bodyfat_entrena_1, media_de)
nrow(bf_entrena_st)
head(bf_entrena_st)
bf_entrena_st$grasacorp
bf_e <- bf_entrena_st %>%
  gather(variable, valor, edad:grasacorp)

ggplot(bf_e, aes(x=valor)) + facet_wrap(~variable, scales='free_x')+ geom_histogram() 

```



Ajuste de modelo
----
Hacemos mínimos cuadrados para obtener:

```{r}
mod_1 <- lm(grasacorp ~ ., data = bf_entrena_st[, -1] )
display(mod_1)
```


El error de entrenamiento es:

```{r}
sqrt(mean((fitted(mod_1) - bf_entrena_st$grasacorp)^2))
```


Evaluación de las predicciones
---

Y ahora evaluamos el error de predicción. En primer lugar, estandarizamos los datos
de prueba. Nótese que **es necesario usar media y desviación estándar que usamos en 
la fase de entrenamiento**.



```{r, warning=FALSE, message=FALSE}
bodyfat_prueba_st <- estandarizar(bodyfat_prueba, media_de)
```



```{r}
bodyfat_prueba_st$pred <- predict(mod_1, newdata = bodyfat_prueba_st)
qplot(bodyfat_prueba_st$pred)
```



```{r}

ggplot(bodyfat_prueba_st, aes(x=pred, y=grasacorp, label=id)) + geom_point(colour='red') + 
  geom_abline(xintercept=0, slope=1) + geom_text(colour='gray30', size=3,hjust=-0.4 )
bodyfat_prueba_st <- mutate(bodyfat_prueba_st, residual = grasacorp - pred)
```

El caso 39 tiene un error muy grande, ¿por?
```{r}
bodyfat_prueba_st %>% filter(id==39) %>% data.frame
bodyfat_prueba %>% filter(id==39) %>% data.frame
```

Esta es una persona excepcionalmente grande, y está fuera del rango
de las personas que observamos en la muestra de entrenamiento - en principio entonces
no debería sorprendernos que el error sea tan alto. En estos casos, muchas
veces es buena idea identificar atípicos para los que la predicción
puede ser dudosa.

De cualquier forma, nuestra estimación del error de predicción (raíz de error cuadrático medio) es:

```{r}
sqrt(mean(bodyfat_prueba_st$residual^2))
```

Podemos estimar su precisión utilizando bootstrap, por ejemplo:

```{r}
res_2 <- bodyfat_prueba_st$residual^2
bstrap <- function(x, B){
  x_rep <- sapply(1:B, function(i){
    sqrt(mean(sample(x, length(x), replace=T)))
  })
  sd(x_rep)
}
bstrap(res_2, 200)
```


Finalmente, ¿cómo se desempeña un método como k-vmc?


```{r}
library(kknn)
errores.vmc.prueba <- sapply(1:30, function(i){
  vmc <- kknn(grasacorp~., k=i, train=bf_entrena_st, test = bodyfat_prueba_st)
  sqrt(mean((predict(vmc) - bodyfat_prueba_st$grasacorp)^2))
})
qplot(1:30, errores.vmc.prueba, geom='line') + geom_point()
```

Y vemnos claramente que en este ejemplo no podemos superar el error del modelo de regresión.




### Error en modelo de regresión: discusión

Sospechamos que una de las razones de nuestro erro alto es la varianza.
 Los errores estándar 
grandes de los coeficientes en la corrida de arriba sugiere que la varianza podría estar afectando nuestras predicciones.
Podemos ver esto de manera más simple 
si simulamos distintas muestras de entrenamiento usando bootstrap y consideramos
la variación de las predicciones. Tenemos que hacer la cadena de preparación:


```{r, message=FALSE}
set.seed(28)
ajustar.modelo <- function(){
    dat_ind <- data_frame(id = sample(bodyfat$id, N, replace = T))
    dat_rep <- left_join(dat_ind, bodyfat)
    dat_rep$id <- 1:nrow(dat_rep)
    bf_e <- dat_rep %>%
      gather(variable, valor, -id)
    media_de <- bf_e %>%
      group_by(variable) %>%
      summarise(media = mean(valor), de = sd(valor))
    bodyfat_entrena_st <- estandarizar(dat_rep, media_de)
    lm(grasacorp ~ ., data = bodyfat_entrena_st[,-1])
    }

modelos <- lapply(1:50, function(i){
  ajustar.modelo()
})
```

Podemos extraer los coeficientes con
```{r}
coeficientes.lista <- lapply(1:50, function(i){
  mod <- modelos[[i]]
  df <- data.frame(t(coef(mod)))
  df$rep <- i
  df
}) 
coefs.1 <- rbind_all(coeficientes.lista) %>%
  dplyr::select(-X.Intercept.) %>%
  gather(variable, coeficiente, edad:peso.kg)
coefs.1$variable <- reorder(coefs.1$variable, abs(coefs.1$coeficiente), mean)
ggplot(coefs.1, aes(x=variable, y=coeficiente, group=rep)) + geom_point() +
  geom_line(alpha=0.2)+ coord_flip()

```


Y notamos que hay variación considerable en varios de los coeficientes: ver por ejemplo
peso.kg, cadera, abdomen y pecho. Esta variabilidad en los coeficientes se puede traducir
a variabilidad en la predicción, lo que a su vez resulta en error de predicción más alto. En algunos casos, los coeficientes toman valores que demasiado grandes (positivos o negativos) y son poco creíbles.


### Regresión ridge

Ahora repetimos el análisis usando regresión regularizada según ridge.

```{r}
X <- dplyr::select(bf_entrena_st, -id, -grasacorp) %>% as.matrix()
X_prueba <- dplyr::select(bodyfat_prueba_st, -id, -grasacorp, -pred,-residual) %>% as.matrix()
y <- bf_entrena_st$grasacorp
y_prueba <- bodyfat_prueba_st$grasacorp
mod_ridge <- glmnet(x=X, y=y, alpha=0.0, lambda =exp(seq(-10,10,1)), standardize=FALSE)
plot(mod_ridge, xvar = "lambda")
```


```{r}
preds <- predict(mod_ridge, newx = X_prueba) %>%
  as.data.frame 
preds$id <- bodyfat_prueba$id
preds <- preds %>% gather(lambda_num, pred, -id) %>%
  left_join(dplyr::select(bodyfat_prueba, id, grasacorp)) 
  
ggplot(preds %>% filter(lambda_num %in% c('s1','s5','s10','s15','s20')), 
       aes(x=grasacorp, y= pred)) + geom_point() + facet_wrap(~lambda_num)+
  geom_abline(slope=1, xintercept=0, colour='red')
```


Y ahora calculamos errores de prueba:

```{r}
error_prueba <- 
preds %>% group_by(lambda_num) %>%
  summarise(error = sqrt(mean((grasacorp-pred)^2)))
ggplot(error_prueba, aes(x=lambda_num, y=error))+ geom_point(size=4.5)
  
```

Finalmente, veamos cómo se ven los coeficientes del mejor modelo:

```{r}
coef(mod_ridge)[, 's9']
coef(mod_1)
```

Nótese que estos son coeficientes no estandarizados. Estos los compararíamos con

```{r}

```

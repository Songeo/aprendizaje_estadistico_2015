---
title: "Error cuadrático: sesgo y varianza en predicción"
author: "Felipe González"
date: Otoño 2015
output: 
  html_document: 
    theme: united
---

Ilustraremos la descomposición de sesgo y varianza con datos simulados. Usar datos simulados
en este ejemplo es importante, pues nos permite ver qué sucede con *distintas muestras de entrenamiento*,
como vimos en la teoría.


```{r setup, include = FALSE}
library(knitr)
library(ggplot2)
library(dplyr)
library(tidyr)
options(digits=2)
```

### Datos
Usaremos los datos que vimos en la clase 2:


```{r }
f <- function(x){
  sin(2*pi*x) + cos(2*pi*x) 
}
simular  <- function(n_muestra, sd){
  x <- runif(n_muestra, 0, 1) 
  y <- f(x) + rnorm(length(x), mean = 0, sd = sd_mod)
  data.frame(x, y)
}
set.seed(2802) 
sd_mod <- 0.8
n_entrena <- 40
datos <- simular(n_entrena, sd_mod)
datos
```

```{r, fig.width=10}
x_plot <- seq(0,1,0.01)
y_plot <- f(x_plot)
ggplot(datos, aes(x=x, y=y), colour='red')+
  geom_point() +
  annotate("line", x=x_plot, y=y_plot, linetype="dotted")
```

Para una muestra de entrenamiento, obtenemos algo como sigue, como vimos en la clase 2:

```{r }
ajuste_mod <- function(datos, m){
  lm(y ~ poly(x, degree=m), data = datos) 
}
modelos <- lapply(1:9, function(i) ajuste_mod(datos, i))
datos_graf_lista <- lapply(1:9, function(i){
   df <- data.frame(grado = i,  x=x_plot , 
        prediccion = predict(modelos[[i]], newdata = data.frame(x=x_plot)),
        esperado = y_plot)
    df   
})
datos_graf <- rbind_all(datos_graf_lista)

dat <- datos_graf %>% gather(variable, valor, prediccion:esperado)
ggplot(dat, aes(x=x, y=valor, linetype=variable )) + 
    geom_line() +
    facet_wrap(~grado) + 
    ylim(c(-3,3)) + 
    annotate("point",x=datos$x, y=datos$y, colour="black")
```

### ¿Cómo varían los modelos según la muestra de entrenamiento?

Ahora tenemos que correr este ejemplo con varias muestras
de entrenamiento (de tamaño fijo). Por ejemplo, en la siguiente gráfica vemos como parece
haber más sensibilidad de los modelos de grado alto a la muestra de entrenamiento. También vemos que los modelos de grado bajo tienen
sesgo (están consistententemente alejados del verdadero valor en la curva punteada): 

```{r, warning=FALSE}

datos_graf_lista <- function(){
  datos <- simular(n_entrena, sd_mod)
  modelos <- lapply(1:9, function(i) ajuste_mod(datos, i))
  salida <- lapply(1:9, function(i){
    df <- data.frame(grado = i,  x=x_plot , 
        prediccion = predict(modelos[[i]], newdata = data.frame(x=x_plot)),
        esperado = y_plot)
    df   
  })
  salida}

datos_graf <- lapply(1:5, function(i) { 
  dat <- rbind_all(datos_graf_lista())
  dat$rep <- i
  dat
  }) %>% rbind_all

dat <- datos_graf %>% gather(variable, valor, prediccion:esperado)
ggplot(dat, 
       aes(x=x, y=valor,  linetype = variable, colour=variable,
           group=interaction(rep, grado, variable) )) + 
    geom_line(alpha=1) +
    facet_wrap(~grado) + 
    ylim(c(-3,3)) 
```

### Sesgo y varianza en la predicción.

En primer lugar, extraemos predicciones en algunos puntos del eje x, y juntamos todas las predicciones.

```{r}
# muestra de prueba fija.
x_0 <- c(0.2, 0.6, 0.9)
simular_y <- function(x, sd_mod){
  y <- f(x) + rnorm(length(x), mean = 0, sd = sd_mod)
  y
}
set.seed(7205)
salida_sim_lista <- lapply(1:2000, function(i){
    # simular muestra de entrenamiento
    datos <- simular(n_muestra = n_entrena, sd_mod)
    # ajustar polinomios
    preds <- lapply(1:9, function(m){
            mod <- lm(y ~ poly(x, degree=m), data = datos)
            data.frame(grado = m, x = x_0, f = f(x_0), 
                       y = simular_y(x_0, sd_mod),
                       preds = predict(mod, data.frame(x=x_0)))
    })
    df <- rbind_all(preds)
    df$rep <- i
    df
})
salida_sim <- rbind_all(salida_sim_lista)
```

Esta tabla tiene en `rep` el número de simulación, en `grado` el
grado del polinomio ajustado, en `x` el valor en el eje x, en `f`
el verdadero valor en `x` correspondiente, y en `preds` la predicción del modelo.

```{r}
head(salida_sim)
```

Con estos datos podemos calcular error de predicción en un punto, junto
con el sesgo y la varianza en ese punto. Para hacer esto
promediamos sobre las repeticiones:


```{r, fig.width=10}
salida <- salida_sim %>% group_by(grado, x, f) %>%
  summarise(media = mean(preds), varianza = var(preds), epe = mean((y-preds)^2)) %>%
  mutate(sesgo2 = (f-media)^2)
salida_v <- salida %>% select(grado, x, varianza:sesgo2) %>%
  gather(componente, valor, varianza:sesgo2)
ggplot(filter(salida_v, grado <= 8), 
       aes(x=grado, y=valor, colour=componente )) +
  geom_point(size=3) +  facet_wrap(~x) + geom_line(size=1.1)  
```

 - Para grado alto, el problema tiende a ser la varianza.
 - Para grado bajo, el problema tiende a ser el sesgo.

Verificamos numéricamente la descomposición sesgo-varianza:

```{r}
salida$diff <- salida$epe - (salida$sesgo2 + salida$varianza)
salida %>% 
  filter(grado <= 8) %>%
  group_by(grado, x) %>%
  summarise(media_diff=mean(diff), media_epe = mean(epe)) %>% print(n=100)
sd_mod^2
```




